#!/usr/bin/env python
from __future__ import print_function
import argparse
import errno
import getpass
import logging
logging.basicConfig(level=logging.INFO) #WARNING
import multiprocessing
import os
import os.path
import shutil
import sys
import time
import zipfile

import numpy
numpy.set_printoptions(precision=2, linewidth=100)

# import non-standard packages
try:
    import openbabel
except ImportError:
    print("OpenBabel not found in your PYTHONPATH environment variable.")
    sys.exit()

try:
    import fragit
except ImportError:
    print("FragIt not found in your PYTHONPATH environment variable.")
    sys.exit()
else:
    import fragit.fragmentation

try:
    import calcit
    import calcit.process
except ImportError:
    print("CalcIt not found in your PYTHONPATH environment variable.")
    sys.exit()

try:
    import pepytools
except ImportError:
    print("pepytools not found in your PYTHONPATH environment variable.")
    sys.exit()
else:
    import pepytools.util
    import pepytools.fields

has_h5py = False
try:
    import h5py
except ImportError:
    print("Warning: HDF5 not found. PDE calculations not supported.")
else:
    has_h5py = True

# custom molecule class
from spectre.molecule import Molecule, Atom
from spectre.molecule.formatters import XYZFormatter
import spectre.errors
import spectre.readers

aa2au = 1.8897261249935897
au2ev = 27.21138602

__doc__ = """
SPECTRE computes absorption spectra of chromophores in heterogenous
environments.

SPECTRE uses a three-step procedure to compute the exciton state of a molecule:
1) Compute embedding potential of ALL molecules in the input.
2) Compute excited state properties of each of the chromophores.
3) Assemble and compute elements of the Foerster matrix from 2) to obtain
   the coupled excited state spectrum of the chromophores.
"""


class DALTONLoPropJob(calcit.dalton.DALTONJob):
    """ A DALTON job to calculate LoProp properties
    """
    def __init__(self, basename, **kwargs):
        """ Initializes a DALTON LoProp calculation

            Arguments:
            basename -- name to use for the job

            Keyword Arguments:
            multipole_order -- order of the distributed multipoles (0 charges, 1 charges + dipoles, and so on)
            polarizability_order -- order of the polarizabilities. 0 none, 1: isotropic 2: anisotropic
        """
        self.mul_order = kwargs.get('multipole_order', 2) # default to charges, dipoles and quadrupoles
        self.pol_order = kwargs.get('polarizability_order', 2) # default to anisotropic dipole-polarizabilities
        calcit.dalton.DALTONJob.__init__(self, basename, **kwargs)
        self.runtype = 'loprop'

    def _program_substitutions(self):
        """ Substitutes information relevant
            Obtaining the LoProp parameters requires the program to
            know where DALTON is and where LoProp Is.
        """
        self._run_script_substitutions['PATH'] = os.environ.get('PATH')
        self._run_script_substitutions['LD_LIBRARY_PATH'] = os.environ.get('LD_LIBRARY_PATH')
        self._run_script_substitutions['PROGPATH'] = os.environ.get('DALTON')
        self._run_script_substitutions['LOPROP'] = os.environ.get('LOPROP')
        self._run_script_substitutions['MULMOM'] = "{0:d}".format(self.mul_order)
        self._run_script_substitutions['POLMOM'] = "{0:d}".format(self.pol_order)

    def __str__(self):
        return "DALTON LoProp ({0:s})".format(self.basename)

    def __repr__(self):
        return "DALTONLoPropJob('{0:s}')".format(self.basename)


class DALTONPDEJob(calcit.dalton.DALTONJob):
    """ A DALTON job to calculate PDE properties """
    def __init__(self, basename, **kwargs):
        calcit.dalton.DALTONJob.__init__(self, basename, **kwargs)

    def _program_substitutions(self):
        """ Substitutes information relevant
            Obtaining the LoProp parameters requires the program to
            know where DALTON is and where LoProp Is.
        """
        self._run_script_substitutions['PATH'] = os.environ.get('PATH')
        self._run_script_substitutions['LD_LIBRARY_PATH'] = os.environ.get('LD_LIBRARY_PATH')
        self._run_script_substitutions['PROGPATH'] = os.environ.get('DALTON')


class DALTONPDEMonomerJob(DALTONPDEJob):
    """ A DALTON job to calculate PDE properties """
    def __init__(self, basename, **kwargs):
        DALTONPDEJob.__init__(self, basename, **kwargs)
        self.runtype = 'pde_monomer'


    def __str__(self):
        return "DALTON PDE Monomer ({0:s})".format(self.basename)


    def __repr__(self):
        return "DALTONPDEMonomerJob('{0:s}')".format(self.basename)


class DALTONPDEDimerJob(DALTONPDEJob):
    """ A DALTON job to calculate PDE properties """
    def __init__(self, basename, **kwargs):
        DALTONPDEJob.__init__(self, basename, **kwargs)
        self.runtype = 'pde_dimer'


    def __str__(self):
        return "DALTON PDE Dimer ({0:s})".format(self.basename)


    def __repr__(self):
        return "DALTONPDEDimerJob('{0:s}')".format(self.basename)


class DALTONPEExEnergyJob(calcit.dalton.DALTONJob):
    """ A DALTON job to calculate embedded (PE) excitated state calculations
    """
    def __init__(self, basename, **kwargs):
        self.nexcited_states = kwargs.get('nexcited_states', 4)
        calcit.dalton.DALTONJob.__init__(self, basename, **kwargs)
        self.runtype = 'peex'

    def _program_substitutions(self):
        """ Substitutes information relevant
            Obtaining the LoProp parameters requires the program to
            know where DALTON is and where LoProp Is.
        """
        self._run_script_substitutions['PATH'] = os.environ.get('PATH')
        self._run_script_substitutions['LD_LIBRARY_PATH'] = os.environ.get('LD_LIBRARY_PATH')
        self._run_script_substitutions['PROGPATH'] = os.environ.get('DALTON')

        self._comp_chem_substitutions['NEXCITATIONS'] = self.nexcited_states

    def __str__(self):
        return "DALTON PE-EX ({0:s})".format(self.basename)

    def __repr__(self):
        return "DALTONPEExEnergyJob('{0:s}')".format(self.basename)


class SpectreExcitedStateData(object):
    """ Representation of excited state data in SPECTRE """

    def __init__(self):
        self._excitation_energies = [] # excitation energies
        self._tr_dips = [] # transition dipoles
        self.tr_q = [] # transition density fitted charges

    @classmethod
    def from_data(cls, de, tr_d, tr_q):
        """ Initiates the SpectreExcitedStateData class from data

            :param de: excitation energies
            :type de: list[float]
            :param tr_d: transition dipoles
            :type tr_d: list[list[float]]
            :param tr_q: transition density fitted charges
            :type tr_q: list[float]

            :return: A populated SpectreExcitedStateData class
        """
        a = cls()
        a.set_excitation_energies(de)
        a.set_transition_dipoles(tr_d)
        a.set_transition_density_fitted_charges(tr_q)
        return a

    def get_number_of_excited_states(self):
        return len(self._excitation_energies)

    def get_excitation_energies(self):
        if len(self._excitation_energies) == 0:
            raise spectre.errors.SpectreExcitedStateValueError("No excitation energies stored.")

        return self._excitation_energies

    def set_excitation_energies(self, value):
        self._excitation_energies = numpy.array(value)

    def get_transition_dipoles(self):
        return self._tr_dips

    def set_transition_dipoles(self, value):
        self._tr_dips = numpy.array(value)

    def get_transition_density_fitted_charges(self):
        return self.tr_q

    def set_transition_density_fitted_charges(self, value):
        self.tr_q = numpy.array(value)

    def get_oscillator_strengths(self):
        """ Computes and returns the oscillator strengths of excitation

            The oscillator strenth is computed from 2/3 dE |mu|

            where dE is an excitation energy and mu is the corresponding
            transition dipole moment.

            Returns:
            oscillator strengths for all excitations
        """
        osc = []
        for e, d in zip(self.get_excitation_energies(), self.get_transition_dipoles()):
            osc.append( 2.0/3.0 * e * d.dot(d))

        return numpy.array(osc)

    def __str__(self):
        line = "@  1{0:>7d}{1:11.4f}{2:14.4f}{3:9.4f}{4:12.3f}{5:9.3f}{6:9.3f}\n"
        s = ""
        for i, (e, d) in enumerate(zip(self._excitation_energies, self._tr_dips), start=1):
            s += line.format(i, e, 0.0, 2./3.*e*d.dot(d), 0.0, 0.0, 0.0)
        return s


class ExpandPath(argparse.Action):
    """ Custom ArgumentParser action to expand absolute paths """
    def __call__(self, parser, namespace, values, option_string=None):
        if values is None:
            setattr(namespace, self.dest, None)
        else:
            setattr(namespace, self.dest, os.path.abspath(values))


def header(text, level, default_width=50):
    """ utility function to generate header strings """
    min_width = len(text) * 2
    width = max(default_width, min_width)
    if level == 0:
        outer_bar = "+{0:s}+".format("".join((width-2)*["-"]))
        inner_bar = "|{0:s}|".format("".join((width - 2) * ["-"]))
        fmts = "{0:s}\n{1:s}\n|{2:^" + "{0:d}".format(width-2) + "}|\n{1:s}\n{0:s}"
        return fmts.format(outer_bar, inner_bar, text)

    if level == 1:
        width = min(default_width, min_width)
        bar = "".join(width*["-"])
        fmts = "{0:s}\n{1:^" + "{0:d}".format(width) + "}\n{0:s}"
        return fmts.format(bar, text)
    elif level == 2:
        return "**** {0:s} ****".format(text)

# ---------------------------------------------
# ---------------------------------------------
# ---------------------------------------------


def setup_chromophores(args):
    """ Slim version of PEAS to generate potentials

        This method performs many tasks:

          - extract chromophores from the supplied input
          - generate potentials from the supplied input
            following ideas from PEAS albeit in a way
            more restricted form
          - Generate the PCM surface for use in PCM
            calculations

        Returns:
        lists of molecules, chromophore indices, potentials and a pcm surface
    """
    if args.verbose:
        print(header("GENERATING POTENTIALS", 0))

    # first step is to fragment everything
    if args.verbose:
        print(">>>> OUTPUT FROM FRAGIT <<<<")
    molecule = obmolecule_from_filename_and_format(args.input)
    fragmentation = fragit.fragmentation.Fragmentation(molecule, conffile=args.frag_settings, verbose=False)
    fragmentation.setVerbose(args.verbose)
    fragmentation.beginFragmentation()
    fragmentation.doFragmentation()
    fragmentation.finishFragmentation()

    if args.verbose:
        print(">>>> END <<<<")
        print()

    # molecule representation of each fragment
    molecules = list(generate_molecules(molecule, fragmentation, args))

    # generate LoProp embedding potentials
    potentials, names = generate_loprop_potentials(molecules, args)

    # make a subset of fragments that are chromophores
    # and their surrounding potentials
    chromophores = [i for i, x in enumerate(molecules) if x.getName() in args.c]

    return molecules, chromophores, potentials


def obmolecule_from_filename_and_format(filename, file_format='pdb'):
    """ Loads a molecule into an OpenBabel molecule.

        Arguments:
        filename -- the file to load
        file_format -- file format to load

        Returns:
        OpenBabel OBMol instance of the molecule
    """
    obc = openbabel.OBConversion()
    obc.SetInFormat(file_format)
    mol = openbabel.OBMol()
    obc.ReadFile(mol, filename)
    return mol


def generate_molecules(obmol, frag, args):
    """ Generates all molecules based on fragmenation

        Arguments:
        obmol -- openbabel molecule
        frag -- FragIt fragmentation of that molecule
        args -- spectre options
    """
    frag_indices = frag.getFragments()
    frag_names = frag.getFragmentNames()
    frag_charges = frag.getFragmentCharges()
    for i, (name, indices, charge) in enumerate(zip(frag_names, frag_indices, frag_charges)):
        yield build_molecule_from_fragment(obmol, indices, name, charge, args)


def build_molecule_from_fragment(obmol, atom_indices, name, charge, args):
    """ Builds molecule from fragmentation data

        Arguments:
        obmol -- openbabel molecule of entire structure
        atom_indices -- atom indices to be extracted from obmol
        name -- name of molecule from .pdb file
        charge -- charge of molecule
        args -- spectre options

        Returns:
        the molecule
    """
    mol = Molecule()
    mol.setName(name)
    mol.setCharge(charge)

    for atom_index in atom_indices:
        obatom = obmol.GetAtom(atom_index)
        mol.addAtom(Atom(obatom.GetAtomicNum(),
                    xyz=[obatom.GetX(), obatom.GetY(), obatom.GetZ()]))

    return mol


def generate_loprop_potentials(molecules, args):
    """ Generates potentials for all molecules in argument list

        SPECTRE uses the CalcIt framework to process individual jobs

        Arguments:
        molecules -- structures which is used to generate embedding potentials
        args -- spectre options

        Returns:
        list of potentials corresponding to the molecules on input
    """

    if args.verbose:
        print(header("LoProp Settings:", 1))

        functional = "RHF"
        if args.potential_functional is not None:
            functional = args.potential_functional
        print_option("theory", "{0}/{1}".format(functional, args.potential_loprop_basis), "{0:s}")

        stat_pot = "charges, dipoles and quadrupoles"
        dyna_pot = "electric dipole-dipole polarizabilities"
        if args.do_isopol:
            dyna_pot = "isotropic electric dipole-dipole polarizabilities"

        if not args.do_polarization:
            dyna_pot = "none"

        print_option("static potential", stat_pot, "{0:s}")
        print_option("dynamic potential", dyna_pot, "{0:s}")
        print("")
        if args.potential_loprop_script is not None:
            print_option("custom run script", args.potential_loprop_script, "{0:s}")
            print("")

        print_option("jobs per node", args.potential_jobs_per_node, "{0:d}")
        print_option("cpus per job", args.potential_cpus_per_job, "{0:d}")
        print("")

    # base working directory for job
    base = os.path.splitext(args.input)[0]
    safe_create_dir(base)
    os.chdir(base)

    # generate calcit jobs for DALTON LoProp calculation
    jobs, job_names = build_calcit_dalton_loprop_jobs(molecules, args)

    # process jobs
    port = 2048
    authorization_key = calcit.util.generate_auth_key("auto")
    nodes = build_hostlist(args.potential_jobs_per_node, args.potential_cpus_per_job, args)
    jobs_per_node = args.potential_jobs_per_node
    work_dir = os.getcwd()
    remote_shell = 'ssh'
    calcit_paths = calcit.util.directories(os.environ['CALCIT'] + '/bin/calcit')
    do_execute = not args.is_dryrun

    calcit.process_jobs(port, authorization_key,
                        jobs, nodes, jobs_per_node,
                        work_dir, remote_shell,
                        calcit_paths, do_execute)

    # now all the initial loprop files should be ready, let us generate
    # potentials needed for embedding calculations later on.
    potentials = [build_loprop_potential(molecule, name) for molecule, name in zip(molecules, job_names)]
    return potentials, job_names


def print_option(key, value, val_fmt, indent=2, width=27):
    indent_width = indent + 4
    indent_fmt = "{0:>" + str(indent + 4) +"s}"
    fmt_key = indent_fmt.format("{0:<") + "{0:d}".format(width-indent) + "s}:"
    fmt_value = val_fmt.format(value)
    print(fmt_key.format(key) + " " + fmt_value)


def build_calcit_dalton_loprop_jobs(molecules, args):
    """ Builds DALTON LoProp jobs and files for calcit

        WARNING: The `job_names` array is used to construct _ALL_ the potentials
                 later and cannot be altered or used to create a shorter list.
                 However, since `job_names` below must _always_ have _all_
                 possible names, but the `jobs` array can be shorter.

        Arguments:
        molecules -- structures which is used to generate embedding potentials
        args -- spectre options

        Returns:
        list of jobs for calcit and associated list of job names.
    """
    job_names = []
    jobs = []
    for i, molecule in enumerate(molecules, start=1):
        name = "{0:04d}_{1:s}".format(i, molecule.getName())

        # unpack a potential zipfile with properties of a single
        # molecule: potential and possible excitation calculations.
        if zipfile.is_zipfile(name + ".zip"):
            with zipfile.ZipFile(name + ".zip") as zf:
                zf.extractall()

        # building a potential is free provided the necessary files are there
        # so we will check for any exceptions raised during attempting to
        # build a potential (but wait for later to actually build it)
        try:
            build_loprop_potential(molecule, name)
        except (OSError, IOError) as e:
            if type(e) is OSError:  # directory is not created
                safe_create_dir(name)

            if type(e) is IOError:  # log-file is not found but we managed to change dir
                os.chdir('..')

            os.chdir(name)
            jobs.append(build_calcit_dalton_loprop_job(molecule, name, args))
            os.chdir("..")
        finally:
            # we always add the job name because we need it for later
            job_names.append(name)

    return jobs, job_names


def safe_create_dir(path):
    """ Creates a directory safely

        If the directory already exists no error is thrown but in any other case
        the error is re-raised

        Arguments:
        path -- the path to create
    """
    try:
        os.makedirs(path)
    except OSError as e:
        if e.errno != errno.EEXIST:
            raise


def build_calcit_dalton_loprop_job(molecule, name, args):
    """ Sets up a LoProp calculation through DALTON

        Arguments:
        molecule -- the molecule
        name -- name of the molecule internally to spectre
        args -- spectre options

        Returns:
        DALTON LoProp Job
    """

    write_molecule_to_xyz(molecule, name)

    # compute the different kinds of polarizablities
    pol_order = 2
    if args.do_isopol:
        pol_order = 1
    if not args.do_polarization:
        pol_order = 0

    return DALTONLoPropJob(name,
                           custom_run_script=args.potential_loprop_script,
                           charge=molecule.getCharge(),
                           basis_set=args.potential_loprop_basis,
                           cores_per_job=args.potential_cpus_per_job,
                           scratch_directory=args.scratch_directory,
                           dft_functional=args.potential_functional,
                           multipole_order=args.potential_multipole_order,
                           polarizability_order=pol_order)


def write_molecule_to_xyz(molecule, name):
    """ Writes a molecule to .xyz file

        :param molecule: the molecule to write to xyz file
        :param name: the name of the molecule (will also be the filename)
        :type molecule: Molecule
        :type name: str
    """
    s = "{0:d}\n{1:s}\n".format(molecule.getNumAtoms(), molecule.getName())
    s += XYZFormatter.coordinates(list(molecule.getAtoms()))
    with open("{0:s}.xyz".format(name), 'w') as xyz_file:
        xyz_file.write(s)


def generate_pde_potentials(molecules, chroms, pots, args):
    """ Generates potentials for all molecules in argument list

        SPECTRE uses the CalcIt framework to process individual jobs

        Arguments:
        molecules -- structures which is used to generate embedding potentials
        args -- spectre options

        Returns:
        list of potentials corresponding to the molecules on input
    """

    if args.verbose:
        print(header("PDE Settings:", 1))

        functional = "RHF"
        if args.potential_functional is not None:
            functional = args.potential_functional
        print_option("theory", "{0}/{1}".format(functional, args.potential_pde_basis), "{0:s}")

        if args.potential_pde_mon_script is not None:
            print_option("custom monomer script", args.potential_pde_mon_script, "{0:s}")
        if args.potential_pde_dim_script is not None:
            print_option("custom dimer script", args.potential_pde_dim_script, "{0:s}")
        print("")

        print_option("jobs per node", args.potential_jobs_per_node, "{0:d}")
        print_option("cpus per job", args.potential_cpus_per_job, "{0:d}")

    # generate calcit jobs for DALTON PDE Monomer calculations
    jobs, job_names = build_calcit_dalton_pde_monomer_jobs(molecules, chroms, pots, args)

    # process jobs
    port = 2048
    authorization_key = calcit.util.generate_auth_key("auto")
    nodes = build_hostlist(args.potential_jobs_per_node, args.potential_cpus_per_job, args)
    jobs_per_node = args.potential_jobs_per_node
    work_dir = os.getcwd()
    remote_shell = 'ssh'
    calcit_paths = calcit.util.directories(os.environ['CALCIT'] + '/bin/calcit')
    do_execute = not args.is_dryrun

    calcit.process_jobs(port, authorization_key,
                        jobs, nodes, jobs_per_node,
                        work_dir, remote_shell,
                        calcit_paths, do_execute)

    # generate calcit jobs for DALTON PDE Dimer calculations
    jobs, job_names = build_calcit_dalton_pde_dimer_jobs(molecules, chroms, pots, args)

    calcit.process_jobs(port, authorization_key,
                        jobs, nodes, jobs_per_node,
                        work_dir, remote_shell,
                        calcit_paths, do_execute)

    return job_names


def build_calcit_dalton_pde_monomer_jobs(molecules, chroms, pots, args):
    """ Builds DALTON PDE jobs and files for calcit

        WARNING: The `job_names` array is used to construct _ALL_ the potentials
                 later and cannot be altered or used to create a shorter list.
                 However, since `job_names` below must _always_ have _all_
                 possible names, but the `jobs` array can be shorter.

        Arguments:
        molecules -- structures which is used to generate embedding potentials
        args -- spectre options

        Returns:
        list of jobs for calcit and associated list of job names.
    """
    # make potential for everything. Needed to store static part of potential
    all_pot = pots[0]
    for p in pots[1:]:
        all_pot += p

    if args.potential is not None:
        all_pot += args.potential


    # we have two subjobs to complete for each chromophore
    jobs = []
    job_names = []

    for i, ii in enumerate(chroms, start=1):
        mi = molecules[ii]

        i_chrom_name = "{0:04d}_{1:s}".format(i, mi.getName())

        # unpack a potential zipfile with properties of a single
        # molecule: potential and possible excitation calculations.
        for j, (mj, pj) in enumerate(zip(molecules, pots), start=1):
            if i == j:
                continue

            name = "{0:s}_{1:04d}_{2:s}".format(i_chrom_name, j, mj.getName())

            if zipfile.is_zipfile(name + ".zip"):
                with zipfile.ZipFile(name + ".zip") as zf:
                    zf.extractall()

            safe_create_dir(name)
            os.chdir(name)

            all_pot.save('temp.pot')

            with h5py.File("{0:s}_dalton_pde_monomer.h5".format(name), 'w') as h5:
                # store core (chromophore) properties
                try:
                    core = h5.create_group("core_fragment")
                except ValueError: # group already exists
                    core = h5['core_fragment']
                finally:
                    core['num_nuclei'] = mi.getNumAtoms()
                    core['charges'] = [a.getNuclearCharge() for a in mi.getAtoms()]
                    core['coordinates'] = mi.getCoordinates()

                # store properties of other fragment
                try:
                    fragment = h5.create_group("fragment")
                except ValueError:  # group already exists
                    fragment = h5['fragment']
                finally:
                    fragment['num_nuclei'] = mj.getNumAtoms()
                    fragment['charges'] = list([a.getNuclearCharge() for a in mj.getAtoms()])
                    fragment['coordinates'] = mj.getCoordinates()

            write_molecule_to_xyz(mj, name)
            jobs.append(build_calcit_dalton_pde_monomer_job(mj, name, args))
            job_names.append(name)

            os.chdir("..")

    return jobs, job_names


#def potential_from_molecule(m):
#    """ Builds a potential sans multipole moments and polarizabilities """
#    p = pepytools.Potential()
#    p.setCoordinates(m.getCoordinates())
#    p.setLabels(m.getLabels())
#    return p


def build_calcit_dalton_pde_monomer_job(molecule, name, args):
    return DALTONPDEMonomerJob(name,
                               custom_run_script=args.potential_pde_mon_script,
                               charge=molecule.getCharge(),
                               basis_set=args.potential_pde_basis,
                               cores_per_job=args.potential_cpus_per_job,
                               scratch_directory=args.scratch_directory,
                               dft_functional=args.potential_functional,
                               )


def build_calcit_dalton_pde_dimer_jobs(molecules, chroms, pots, args):
    """ Builds DALTON PDE jobs and files for calcit

        WARNING: The `job_names` array is used to construct _ALL_ the potentials
                 later and cannot be altered or used to create a shorter list.
                 However, since `job_names` below must _always_ have _all_
                 possible names, but the `jobs` array can be shorter.

        Arguments:
        molecules -- structures which is used to generate embedding potentials
        args -- spectre options

        Returns:
        list of jobs for calcit and associated list of job names.
    """
    # make potential for everything. Needed to store static part of potential
        # we have two subjobs to complete for each chromophore
    jobs = []
    job_names = []

    for i, ii in enumerate(chroms, start=1):
        mi = molecules[ii]

        i_chrom_name = "{0:04d}_{1:s}".format(i, mi.getName())

        for j, (mj, pj) in enumerate(zip(molecules, pots), start=1):
            if i == j:
                continue

            name = "{0:s}_{1:04d}_{2:s}".format(i_chrom_name, j, mj.getName())
            os.chdir(name)

            # also dump .xyz file with combined molecule
            mol_combined = Molecule.fromMolecule(mi)
            mol_combined.addAtoms(*list(mj.getAtoms()))
            write_molecule_to_xyz(mol_combined, name)

            jobs.append(build_calcit_dalton_pde_dimer_job(mol_combined, name, args))
            job_names.append(name)

            os.chdir("..")

    return jobs, job_names


def build_calcit_dalton_pde_dimer_job(molecule, name, args):
    return DALTONPDEDimerJob(name,
                               custom_run_script=args.potential_pde_dim_script,
                               charge=molecule.getCharge(),
                               basis_set=args.potential_pde_basis,
                               cores_per_job=args.potential_cpus_per_job,
                               scratch_directory=args.scratch_directory,
                               dft_functional=args.potential_functional,
                               )


def build_hostlist(njpn, ncpj, args):
    """ Build and return hostlist

        if running through the SLURM queue system on a compute cluster
        the system will spawn jobs on each node assigned to the job

        Info:
        Only implemented for localhost and SLURM.

        Returns:
        the nodelist to use for jobs
    """

    # by default, we just assume that we are running
    # on one node (i.e. the one we are running on)
    nodes = ['localhost'] # [socket.gethostname()]

    slurm_nodelist = os.environ.get("SLURM_NODELIST", None)
    if slurm_nodelist is not None:
        o, e, dt = calcit.process.execute("scontrol show hostname")
        nodes = list(set(o.split()))

    return nodes


def build_loprop_potential(mol, name):
    """ Builds a potential file from the LoProp data

        and optionally (currently never) writes it to disk.

        This method can raise two different exceptions:
        IOError -- if the file is not found
        OSError -- if the scratch directory is not found

        Arguments:
        mol -- the molecule for which to construct the potential for
        name -- the name (base of filename) of the file associated with the molecule

        Returns:
        The potential
    """
    os.chdir(name)
    potential = potential_from_loprop_data(mol, name)
    os.chdir("..")
    return potential


def build_pde_potential(mol, name):
    """ Builds a potential file from the PDE data

        and optionally (currently never) writes it to disk.

        This method can raise two different exceptions:
        IOError -- if the file is not found
        OSError -- if the scratch directory is not found

        Arguments:
        mol -- the molecule for which to construct the potential for
        name -- the name (base of filename) of the file associated with the molecule

        Returns:
        The potential
    """
    print("building PE potential")
    os.chdir(name)
    raise IOError

    #potential = potential_from_loprop_data(mol, name)
    # if False:
    #    with open("{0:s}.pot".format(name), 'w') as pot_file:
    #        pot_file.write(str(potential))

    os.chdir("..")
    return None


def potential_from_loprop_data(mol, name):
    """ Reads a LoProp data file and constructs a potential from it

        Arguments:
        mol -- the molecule for which to construct the potential for
        name -- the name (base of filename) of the file associated with the molecule

        Returns:
        The potential
    """
    mul_offset = {0: 1, 1: 3, 2: 6}
    pol_offset = {1: 1, 2: 6}

    mul_data = {}
    pol_data = []

    coords = mol.getCoordinates() * aa2au
    labels = [atom.getLabel() for atom in mol.getAtoms()]

    filename = "{0:s}_dalton_loprop.loprop".format(name)
    with open(filename, 'r') as loprop_file:
        line = loprop_file.readline()  # AA or AU
        if "AA" in line:
            raise spectre.errors.SpectrePotentialValueError("Expected units to be in AU.")

        nat, lmax, amax, dum = map(int, loprop_file.readline().split())
        if nat == 0:
            raise spectre.errors.SpectrePotentialValueError("No atoms found.")
        if lmax > 2:
            raise spectre.errors.SpectrePotentialValueError("Only supports up to quadrupoles.")
        if amax > 2:
            raise spectre.errors.SpectrePotentialValueError("Does not support polarizability tensors with dim > 2.")

        for i in range(nat):
            # skip coordinates in the data
            tokens = map(float, loprop_file.readline().split()) [4:]
            for l in range(lmax+1):
                if not mul_data.has_key(l):
                    mul_data[l] = []

                offset = mul_offset[l]
                mul_data[l].append(tokens[0:offset])
                tokens = tokens[offset:]

            if amax == 0:
                continue

            if len(tokens) == pol_offset[amax]:
                if len(tokens) == 1:
                    pol_data.append([tokens[0], 0.0, 0.0, tokens[0], 0.0, tokens[0]])
                else:
                    pol_data.append(tokens)
            else:
                raise spectre.errors.SpectrePotentialValueError("Nope")

    pot = pepytools.Potential()
    pot.coordinates = coords
    pot.labels = labels
    pot.multipoles = mul_data

    #
    if len(pol_data) > 0:
        excl_data = {}
        serials = range(mol.getNumAtoms())
        for i in serials:
            excl_atom = []
            for j in serials:
                if i == j:
                    continue

                excl_atom.append(j)
            excl_data[i] = numpy.array(excl_atom)

        pot.polarizabilities = pol_data
        pot.exclusion_list = excl_data

    return pot

# ---------------------------------------------
# ---------------------------------------------
# ---------------------------------------------


def compute_chromophores(mols, pots, chroms, args):
    """ Computes excited state properties for the supplied
        list of chromophores

        Arguments:
        mols -- list of molecules in system
        pots -- embedding potentials for all molecules
        chros -- list of chromophores to evaluate
        args -- spectre settings object
    """

    if args.verbose:
        print(header("COMPUTING CHROMOPHORE EXCITED STATE PROPERTIES", 0))

        print(header("Excited State Settings:", 1))
        functional = "RHF"
        if args.ex_functional is not None:
            functional = args.ex_functional
        print_option("theory", "{0}/{1}".format(functional, args.ex_basis), "{0:s}")
        if args.potential is not None:
            print_option("external potential", args.potential, "{0}")

        print_option("chromophore names", "{0}".format(", ".join(args.c)), "{0:s}")
        print_option("number of states", args.ex_n, "{0:d}")

        states = "all"
        if args.ex_state > 0:
            states = "{0}".format(args.ex_state)
        print_option("coupling states", states, "{0}")
        print("")

        if args.ex_script is not None:
            print_option("custom run script", format(args.ex_script), "{}")
            print("")

        print_option("jobs per node", args.potential_jobs_per_node, "{0:d}")
        print_option("cpus per job", args.potential_cpus_per_job, "{0:d}")

    # generate calcit jobs for DALTON calculation
    jobs, job_names = build_calcit_dalton_ex_jobs(mols, pots, chroms, args)


    # process jobs
    port = 2048
    authorization_key = calcit.util.generate_auth_key("auto")
    nodes = build_hostlist(args.ex_jobs_per_node, args.ex_cpus_per_job, args)
    jobs_per_node = args.ex_jobs_per_node
    work_dir = os.getcwd()
    remote_shell = 'ssh'
    calcit_paths = calcit.util.directories(os.environ['CALCIT'] + '/bin/calcit')
    do_execute = not args.is_dryrun

    calcit.process_jobs(port, authorization_key,
                        jobs, nodes, jobs_per_node,
                        work_dir, remote_shell,
                        calcit_paths, do_execute)


    data = compute_chromophore_properties(mols, chroms, job_names, args)
    assert(len(data) == len(chroms))

    s_out = ""
    for i, p in enumerate(data, start=1):
        s_out += "{0:s}\n".format(output_dalton_ex_data(p.get_excitation_energies(), p.get_oscillator_strengths(), idx=i))
    if args.verbose:
        print(s_out)

    if args.write_file:
        base = os.path.splitext(args.input)[0]
        filename = "{0}_uncoupled.dat".format(base)
        with open(filename, "w") as f:
            f.write(s_out)

    return data


def build_calcit_dalton_ex_jobs(molecules, pots, chroms, args):
    """ Builds list of DALTON jobs for excited state calculations

        Arguments:
        molecules -- list of molecules in system
        pots -- embedding potentials for all molecules
        chroms -- list of chromophores to evaluate
        args -- spectre settings object
    """

    #
    #print "build_calcit_dalton_ex_jobs"
    #print "----"
    #print "molecules   :", molecules
    #print "potentials  :", pots
    #print "chromophores:", chroms
    #print "----"
    job_names = []
    jobs = []
    for i, chrom in enumerate(chroms, start=1):
        molecule = molecules[chrom]
        potential = build_chromophore_potential(pots, args, chrom)

        name = "{0:04d}_{1:s}".format(i, molecule.getName())

        safe_create_dir(name)
        os.chdir(name)

        jobs.append(
           DALTONPEExEnergyJob(name,
               charge=molecule.getCharge(),
               custom_run_script=args.ex_script,
               basis_set=args.ex_basis,
               cores_per_job=args.ex_cpus_per_job,
               scratch_directory=args.scratch_directory,
               dft_functional=args.ex_functional,
               nexcited_states=args.ex_n)
        )

        potname = jobs[-1].get_jobname()
        with open("{0:s}.pot".format(potname), "w") as pot_file:
            pot_file.write(str(potential))

        job_names.append(potname)
        os.chdir("..")

    if len(jobs) == 0:
        raise spectre.errors.SpectreRuntimeError("No chromophores identified with tag(s) '{}'".format(', '.join(args.c)))

    return jobs, job_names


def compute_chromophore_properties(mols, chroms, job_names, args):
    """ Extracts properties for chromophores from the excited state logfiles

        Arguments:
        mols -- molecules
        chromes -- chromophores
        job_names -- the names of the jobs
        args -- spectre settings object
    """
    assert len(chroms) == len(job_names)

    data = []

    for i, chrom in enumerate(chroms, start=1):
        molecule = molecules[chrom]
        jobname = job_names[chrom]

        name = "{0:04d}_{1:s}".format(i, molecule.getName())

        safe_create_dir(name) # probably not needed
        os.chdir(name)

        try:
            energies, tr_dips, tr_charges = spectre.readers.get_chromophore_peex_data(jobname, args.coupling_with_moments)
        except IOError as e:
            if args.is_dryrun:
                print("You requested --dryrun but the output file '{0:s}.out' was not found.".format(jobname))
                print("Please re-run without --dryrun to compute all files.")
            else:
                print("The file '{0:s}.out' was not found. There could be a problem with the calculation so please check all output in the folder {1:s}.".format(jobname, name))
            exit()
        else:
            data.append(SpectreExcitedStateData.from_data(energies, tr_dips, tr_charges))

        os.chdir("..")

    return data

# ---------------------------------------------
# ---------------------------------------------
# ---------------------------------------------


def couple_chromophores(molecules, chromophores, potentials, properties, args):
    """ Computes the exciton states for the chromophores.

        :param molecules: all molecules in the system
        :type molecules: list[Molecule]
        :param chromophores: chromohores in the system
        :type chromophores: list
        :param potentials: all potentials for all molecules in the system
        :type potentials: list
        :param properties: chromophore properties
        :type properties: list

        :return: exciton energies, transition dipoles and oscillator strengths
        :rtype: (list[float], list[list], list[float])
    """

    if args.verbose:
        print(header("COMPUTING COUPLINGS", 0))

        print(header("Coupling Settings:", 1))
        coupling_mode_str = "transition density fitted {}"
        coupling_orders = {0: 'charges',
                           1: 'charges and dipoles',
                           2: 'charges, dipoles and quadrupoles'}
        coupling_mode = coupling_mode_str.format(coupling_orders[args.coupling_qfit_mom])
        if not args.coupling_with_moments:
            coupling_mode = "transition dipoles"

        couplings_str = "J0"
        if args.do_polarization:
            couplings_str = couplings_str + " + J1"

        coupling_algorithm = "serial"
        if args.coupling_cpus > 1:
            coupling_algorithm = "parallel ({} cores)".format(args.coupling_cpus)
        print_option("couplings", couplings_str, "{0:s}")
        print_option("calculated from", coupling_mode, "{0:s}")
        print_option("algorithm", coupling_algorithm, "{0:s}")

        if args.do_polarization:
            print_option("induced mom. eps", args.coupling_inddip_eps, "{0:6.1e}")

    energies = numpy.ravel([prop.get_excitation_energies() for prop in properties])
    tr_dips = [prop.get_transition_dipoles() for prop in properties]

    # build coupling matrix
    J = compute_total_coupling(molecules, chromophores, potentials, properties, args)
    matstat(J)
    F = numpy.diag(numpy.ravel(energies)) + J

    # diagonalize to get coefficients
    exciton_energies, v = numpy.linalg.eigh(F)

    # we need to ravel the top layer of the tr_dips only
    tr_dips_ravel = []
    for i in range(len(chromophores)):
        for value in tr_dips.pop(0):
            tr_dips_ravel.append(value)

    # exciton transition dipoles and oscillator strengths
    exciton_tr_dips = []
    exciton_osc_str = []
    for i, (ei, vi) in enumerate(zip(exciton_energies, v.T)):
        tr_dip = numpy.zeros(3)
        for c, t in zip(vi, numpy.asarray(tr_dips_ravel)):
            tr_dip += c * t

        exciton_tr_dips.append(tr_dip)
        exciton_osc_str.append(2.0/3.0*ei*tr_dip.dot(tr_dip))

    s_out = output_dalton_ex_data(exciton_energies, exciton_osc_str, idx=1)
    if args.verbose:
        print(s_out)
    if args.write_file:
        base = os.path.splitext(args.input)[0]
        filename = "{0}_coupled.dat".format(base)
        with open(filename, "w") as f:
            f.write(s_out)

    return exciton_energies, numpy.asarray(exciton_tr_dips), numpy.asarray(exciton_osc_str)


def compute_J0(mols, props, ichrom, jchrom, iex, jex, args):
    """
        Arguments:
        mols -- molecules in the system
    """
    # extract the information we need

    imol = mols[ichrom]
    jmol = mols[jchrom]
    coord_i = imol.getCoordinates() * aa2au
    coord_j = jmol.getCoordinates() * aa2au

    tr_q_i = props[ichrom].get_transition_density_fitted_charges()[iex]
    tr_q_j = props[jchrom].get_transition_density_fitted_charges()[jex]

    if args.coupling_with_moments:
        if args.coupling_qfit_mom == 0:
            return J0_tr_q_kernel(coord_i, coord_j, tr_q_i, tr_q_j)
        else:
            raise NotImplementedError("J0 Not implemented for moments higher than charges.")
    else:
        raise NotImplementedError("Transition dipole J0 couplings not implemented yet.")


def compute_J1(mols, pots, props, ichrom, jchrom, iex, jex, args):
    # 1) build potential without I and J in and make it
    #     #    a transition potential (i.e. 0'es in static charge dist)
    potij = build_chromophore_potential(pots, args, ichrom, jchrom)
    potij.make_transition_potential()

    imol = mols[ichrom]
    jmol = mols[jchrom]
    coord_i = imol.getCoordinates() * aa2au
    coord_j = jmol.getCoordinates() * aa2au

    tr_q_i = props[ichrom].get_transition_density_fitted_charges()[iex]
    tr_q_j = props[jchrom].get_transition_density_fitted_charges()[jex]

    # we need the potentials from the two chromophores which are dependent
    # on how we used to compute J0
    if args.coupling_with_moments:
        if args.coupling_qfit_mom == 0:
            poti = pepytools.Potential.from_multipoles(coord_i, tr_q_i)
            potj = pepytools.Potential.from_multipoles(coord_j, tr_q_j)
        else:
            raise NotImplementedError("J1 Not implemented for moments higher than charges.")
    else:
        raise NotImplementedError("Transition dipole J1 couplings not implemented yet.")

    # Solve for A.F(J) (eq 12 in 10.1021/acs.jctc.5b00470)
    AF = potij + potj
    polmat = pepytools.util.get_polarization_matrix(AF)
    intmat = pepytools.util.get_interaction_matrix(AF)
    field = pepytools.fields.get_static_field(AF)
    s = pepytools.solvers.IterativeDIISSolver(polmat, intmat, field, verbose = False, threshold = args.coupling_inddip_eps)
    muind = s.Solve()

    # Now get field at induced dipoles to compute F(I).(A.F(J))
    F = potij + poti
    field = pepytools.fields.get_static_field(F)

    return -field.dot(muind)


def compute_total_coupling(mols, chroms, pots, props, args):
    """ Computes couplings between all chromophores in the system
        according to Steinmann and Kongsted, JCTC (2015),
        DOI: 10.1021/acs.jctc.5b00470

        The coupling between two chromophores is given as

            J = J^{(0)} + J^{(1)}

        where J^{(0)} is the direct (Coulomb) coupling which is calculated from
        partial charges fitted to reproduce the transition density from state
        i to a

            J^{(0)} = sum_{i \in I, j \in J} q_i q_j / |R_i - R_j|

        or from transition dipole moments. A screening effect, J^{(1)}, from
        a polarizable medium is done through

            J^{(1)} = F(I) A F(J)

        where F(I) and F(J) are, respectively, the electric fields at the
        polarizable sites in the environment from chromophore I and
        chromophore J.

        Arguments:
        mols -- all molecules in the system
        chroms -- chromophores in the system
        pots -- all potentials in the system
        props --
        args -- spectre options
    """
    n = len(chroms) * args.ex_n

    J0 = numpy.zeros((n,n))
    J1 = numpy.zeros_like(J0)

    t0 = numpy.asarray(time.time(), dtype=numpy.float64)
    if args.coupling_cpus > 1:
        # parallel version (should be able to run in serial as well)
        indices = []
        j0_jobs = []
        j1_jobs = []
        pool = multiprocessing.Pool(processes=args.coupling_cpus)
        for (chromophore_i, chromophore_j, iex, jex, imat, jmat) in chromophore_pair_ex_iterator(chroms, args):
            indices.append((imat, jmat))
            j0_jobs.append(pool.apply(compute_J0, args=(mols, props, chromophore_i, chromophore_j, iex, jex, args)))
            if args.do_polarization:
                j1_jobs.append(pool.apply(compute_J1, args=(mols, pots, props, chromophore_i, chromophore_j, iex, jex, args,)))

        for i, (imat, jmat) in enumerate(indices):
            J0[imat, jmat] = j0_jobs[i]
            J0[jmat, imat] = J0[imat, jmat]

        if args.do_polarization:
            for i, (imat, jmat) in enumerate(indices):
                J1[imat, jmat] = j1_jobs[i]
                J1[jmat, imat] = J1[imat, jmat]
    else:
        # serial execution
        for (chromophore_i, chromophore_j, iex, jex, imat, jmat) in chromophore_pair_ex_iterator(chroms, args):

            J0[imat, jmat] = compute_J0(mols, props, chromophore_i, chromophore_j, iex, jex, args)
            J0[jmat, imat] = J0[imat, jmat]

            if args.do_polarization:
                J1[imat, jmat] = compute_J1(mols, pots, props, chromophore_i, chromophore_j, iex, jex, args)
                J1[jmat, imat] = J1[imat, jmat]

    t1 = numpy.asarray(time.time(), dtype=numpy.float64)
    if args.verbose:
        print("total coupling time [s]: {0:6.2f}".format(t1 - t0))

    return J0 + J1


def J0_tr_q_kernel(coord_i, coord_j, tr_q_i, tr_q_j):
    """ computes the J0 coupling using partial atomic charges

        The charges are fitted to reproduce the ESP of a transition density
        and are placed on the atoms

        Arguments:
        coord_i -- coordinates of the i'th molecule
        coord_j -- coordinates of the j'th molecule
        tr_q_i -- charges of the i'th molecule
        tr_q_j -- charges of the j'th molecule

        Returns:
        the J0 coupling
    """
    assert len(coord_i) > 0
    assert len(coord_j) > 0
    assert len(coord_i) == len(tr_q_i)
    assert len(coord_j) == len(tr_q_j)
    J0 = 0.0
    for qi, ci in zip(tr_q_i, coord_i):
        for qj, cj in zip(tr_q_j, coord_j):
            dr = cj - ci
            J0 += qi*qj / numpy.sqrt(dr.dot(dr))
    return J0


def build_chromophore_potential(potentials, args, *chroms):
    """ Build potential for chromophores listed in the args list

        Arguments:
        potentials -- all potentials for each part of the system
        args -- spectre settings object

        Variable Arguments:
        chroms -- list of chromophores indices

        note: the construction of a chromophore potential
              is a bit funky because of the way
              the potential class works (or should one say how
              it does not work): We first build the correct list of potentials
              and then add the potentials (in a clunky way).
    """

    idx_potentials = []
    for j, pot in enumerate(potentials):
        if j in chroms:
            continue
        idx_potentials.append(j)


    # idx_potentials is a list of potentials we actually need
    if len(idx_potentials) == 0:
        if args.potential is not None:
            chromophore_potential = pepytools.Potential.from_file(args.potential)
        else:
            raise ValueError("No external potentials defined. Are you sure this [gas phase calculation] is what you want?")
    else:
        idx = idx_potentials[0]

        # external 'constant' potentials are added first
        if args.potential is not None:
            chromophore_potential = pepytools.Potential.from_file(args.potential) + potentials[idx]
        else:
            chromophore_potential = potentials[idx]
        for idx_potential in idx_potentials[1:]:
            chromophore_potential = chromophore_potential + potentials[idx_potential]

    return chromophore_potential


def chromophore_pair_ex_iterator(chroms, args):
    """ Iterator over excitations in pairs of chromophores

        Arguments:
        chroms -- chromophores over which to iterate
        args -- spectre options

        Returns:
        tuple of:
            ith chromophore
            jth chromophore
            kth excitation in ith chromophore
            lth excitation in jth chromophore
            matrix index for kth excitation in ith chromophore
            matrix index for lth excitation in jth chromophore

    """
    for i, chromophore_i in enumerate(chroms):
        for j, chromophore_j in enumerate(chroms):
            if i > j:
                for excitation_i, mat_index_i in enumerate(range(i*args.ex_n, (i+1)*args.ex_n)):
                    for excitation_j, mat_index_j in enumerate(range(j*args.ex_n, (j+1)*args.ex_n)):
                        yield chromophore_i, chromophore_j, excitation_i, excitation_j, mat_index_i, mat_index_j


def matstat(mat):
    """ Computes properties for the input matrix
    """
    i = numpy.argmax(numpy.abs(mat))
    (idx, jdx) = numpy.unravel_index(numpy.abs(mat).argmax(), mat.shape)

    print("MAX Element {2:9.6f} between elements {0:d} and {1:d}".format(idx+1, jdx+1, numpy.ravel(mat)[i]))


def output_dalton_ex_data(energies, oscillator_strengths, idx=1):
    """ Writes a DALTON-like output of spectral properties

        Note: Rotational strengths are not supplied as of now
              but is on the TODO.

        Arguments:
        energies -- Excitation energies
        osc_str -- oscillator strengths

        Optional Argument:
        idx -- the index of the system

        The data format is

        1234567890123456789012345678901234567890123456789012345678901234567890123456789

        @  1      i       dE            XX       osc         XX      R        R_L

        @  1      1     3.2874        0.0000   0.0017       0.000  -12.189  -12.160
        @  1      2     4.1101        0.0000   0.1076       0.000  110.709  110.478
        @  1      3     4.5190        0.0000   0.5327       0.000 -108.546 -109.723
        @  1      4     5.1764        0.0000   0.0012       0.000   -1.910   -1.888
        @  1      5     5.5422        0.0000   0.0019       0.000   -5.130   -5.386
        @  1      6     5.9525        0.0000   0.0149       0.000   -2.226   -2.913
    """
    s = "@  {0:1d}{1:>7d}{2:11.4f}{3:14.4f}{4:9.4f}{5:12.3f}{6:9.3f}{7:9.3f}\n"

    s_out = ""
    for i, (energy, osc_str) in enumerate(zip(energies, oscillator_strengths)):
        s_out += s.format(idx, i+1, energy, 0.0, osc_str, 0.0, 0.0, 0.0)

    return s_out[:-1]


def cleanup_work_directories(mols):
    """ Compresses working folders to zip and removes them

        Scope: work_dir

        Arguments:
        mols -- molecules
        args -- spectre options
    """
    for i, molecule in enumerate(mols, start=1):
        name = "{0:04d}_{1:s}".format(i, molecule.getName())
        shutil.make_archive(name, 'zip', '.', name)
        shutil.rmtree(name)


if __name__ == "__main__":
    # attempt to guess scratch area before calculation even begins
    # if we cannot guess a scratch area report it as an error so
    # the calculation does not fail later
    slurm_scratch = os.environ.get('SCRATCH', None)
    spectre_scratch = os.environ.get('SPECTRE_TMPDIR', None)

    scratch_path = None
    scratch_path_str = "{}/SPECTRE_scratch_{}"
    if slurm_scratch is not None:
        scratch_path = scratch_path_str.format(slurm_scratch, getpass.getuser())
    elif spectre_scratch is not None:
        scratch_path = scratch_path_str.format(spectre_scratch, getpass.getuser())

    # check environment variables before computation starts
    # we will report on _ALL_ environment variables before
    # we potentially abort the program
    # a pretty fortran-style way of doing error checking here
    env_errors = 0
    try:
        os.environ['SPECTRE']
    except KeyError:
        print("ERROR: SPECTRE environment variable not pointing to installation share path.")
        env_errors += 1

    try:
        os.environ['CALCIT']
    except KeyError:
        print("ERROR: CALCIT environment variable not pointing to installation path.")
        env_errors += 1

    try:
        os.environ['DALTON']
    except KeyError:
        print("ERROR: DALTON environment variable not set to path of DALTON installation.")
        env_errors += 1

    try:
        os.environ['LOPROP']
    except KeyError:
        print("ERROR: LOPROP environment variable not set to path of LOPROP installation.")
        env_errors += 1

    if env_errors > 0:
        sys.exit("There were errors in the environment variables")

    # The user can set the options for the potential calculations
    # through the --ntasks-per-node and --cpus-per-task options in the SLURM
    # submit script.
    # If not running on SLURM, we default to 1 and the user has
    # to specify this manually.
    pot_jobs_per_node = os.environ.get("SLURM_NTASKS_PER_NODE", 1)
    pot_cpus_per_job = os.environ.get("SLURM_CPUS_PER_TASK", 1)

    # for chromophore excitations we always default to 1 and 1 but the README should
    # specify that this is usually not wanted.
    # NB: Please note that using this setup it is not possible to run a single
    #     DALTON calculation on more than one node.
    chr_jobs_per_node = 1
    chr_cpus_per_job = 1

    # for coupling calculations we default to the serial unless
    # slurm tells us the number of cores on each node
    coup_cpus = os.environ.get("SLURM_JOB_CPUS_PER_NODE", 1)

    ap = argparse.ArgumentParser(description=__doc__)

    ap.add_argument("input", type=str, metavar="FILE", help="Input .pdb file.")
    ap.add_argument("-v", "--verbose", action="store_true", default=False)
    ap.add_argument("-s", "--scratch", dest="scratch_directory", metavar="DIRECTORY", default=scratch_path, help="Base directory for scratch storage. Default is extracted from either SCRATCH or SPECTRE_TMPDIR environment variables. Default %(default)s.")
    ap.add_argument("--dryrun", dest="is_dryrun", action="store_true", default=False, help="Specify this flag to skip any computations in either embedding potential calculations or excited state calculations. If the excited state calculations are present SPECTRE will compute the coupled spectrum.")
    ap.add_argument("--nowrite", dest="write_file", action="store_false", default=True, help="Do not write resulting spectra to files.")

    fragmentation_group = ap.add_argument_group("Fragmentation")
    fragmentation_group.add_argument("-f", type=str, dest='frag_settings', metavar="FILE", default=None, help="")

    potential_group = ap.add_argument_group("Embedding Potential Calculations")
    potential_group.add_argument("-p", dest="potential", default=None, action=ExpandPath, metavar="POTENTIAL", help="Adds a 'constant' PE-potential to the calculation, for example a protein or solvent shell.")
    potential_group.add_argument("--potential-no-pol", dest="do_polarization", default=True, action="store_false", help="Set this flag to disable polarization effects. This will also remove screening in the couplings between chromophores.")
    potential_group.add_argument("--potential-isopol", dest="do_isopol", default=False, action="store_true", help="Set this flag to only do isotropic polarizabilities instead of the full anisotropic polarizabilities.")
    potential_group.add_argument("--potential-multipole-order", type=int, default=2, choices=[0,1,2], help="Highest order multipole moment of the static part of the embedding potential. Choices are: %(choices)s. Default is %(default)s.")
    potential_group.add_argument("--potential-loprop-basis", metavar='BASIS', default="loprop-6-31+G*", help="Basis set to use for LoProp embedding potential calculations. Default is %(default)s.")
    potential_group.add_argument("--potential-functional", metavar='FUNCTIONAL', default=None, help="Selects an DFT functional for excited state calculations. If not specified, HF is chosen as the default.")
    potential_group.add_argument("--potential-loprop-script", default=os.environ['SPECTRE'] +'/share/dalton_loprop.bash', metavar="SCRIPT", action=ExpandPath, help="Script to the LoProp potential for each chromophore. Default: %(default)s.")
    potential_group.add_argument("--potential-jobs-per-node", default=pot_jobs_per_node, type=int, metavar="JOBS_PER_NODE", help="Number of jobs to execute per node for potential calculation. This is number is usually equal to the number of cores available to you on a single node. Can be controlled with SLURM using the --ntasks-per-node option. Default is %(default)s.")
    potential_group.add_argument("--potential-cpus-per-job", default=pot_cpus_per_job, type=int, metavar="CPUS_PER_JOB", help="Number of cores per job. This number is usually low. Can be controlled with SLURM using the --cpus-per-task option. Default is %(default)s.")
    potential_group.add_argument("--potential-do-pde", dest="do_pde", default=False, action="store_true", help="Enables the use of PDEs. Default is false.")
    potential_group.add_argument("--potential-pde-basis", metavar='BASIS', default="6-31+G*", help="Basis set to use for PDE embedding potential calculations. Default is %(default)s.")
    potential_group.add_argument("--potential-pde-mon-script", default=os.environ['SPECTRE'] + '/share/dalton_pde_monomer.bash', metavar="SCRIPT", action=ExpandPath, help="Script to generate momomeric part of PDE potential for each chromophore. Default: %(default)s.")
    potential_group.add_argument("--potential-pde-dim-script", default=os.environ['SPECTRE'] + '/share/dalton_pde_dimer.bash', metavar="SCRIPT", action=ExpandPath, help="Script to generate dimeric part of PDE potential for each chromophore. Default: %(default)s.")

    chr_group = ap.add_argument_group("Excited State Chromophore Calculations")
    chr_group.add_argument("-c", type=str, nargs="+", metavar="NAME", help="Selects residue names to be excitonically coupled.")
    chr_group.add_argument('-r', metavar="DISTANCE", type=float, default=-1.0, help="Select additional fragments within DISTANCE of fragments from -c to be coupled excitonically. Mutually exclusive with -a.")
    chr_group.add_argument('-a', metavar="ID", nargs='+', type=int, help="Appends fragment indices to list of chromophores that are to be coupled excitonically. Mutually exclusive with -r.")
    chr_group.add_argument("-n", dest='ex_n', type=int, metavar="N", default=4, help="Number of excited states N to compute for each chromophore. Default is %(default)s.")
    chr_group.add_argument("--ex-state", type=int, default=0, help="State(s) to couple between chromophores.")
    chr_group.add_argument("--ex-basis", default="pcseg-0", metavar='BASIS', help="Basis set to use for the excited state calculations and coupling parameters. Default is %(default)s.")
    chr_group.add_argument("--ex-functional", default=None, metavar='FUNCTIONAL', help="Selects a density functional for excited state calculations. If not specified, HF is chosen.")
    chr_group.add_argument("--ex-script", default=os.environ['SPECTRE'] +'/share/dalton_excited.bash', metavar="SCRIPT", action=ExpandPath, help="Script to compute excited state calculations. Default: %(default)s.")
    chr_group.add_argument("--ex-jobs-per-node", default=chr_jobs_per_node, type=int, metavar="JOBS_PER_NODE", help="Number of jobs to execute per node for embedded chromophores. This is number is usually lower than the potential counterpart. Default is %(default)s.")
    chr_group.add_argument("--ex-cpus-per-job", default=chr_cpus_per_job, type=int, metavar="CPUS_PER_JOB", help="Number of cores per job. This number should almost always be equal to the number of cores available on your node. Default is %(default)s.")

    cpl_group = ap.add_argument_group("Coupling Parameters", description="""In case there are multiple chromophores selected through the -c keyword or other keywords, the chromophores will electronically couple through a term J = J^0 + J^1 where J^0 is computed always and J^1 depends on the environment. J^1 is always computed unless the environment is static or the --potential-no-pol option has been given.""")
    cpl_group.add_argument("--coupling-trdip", dest="coupling_with_moments", default=True, action="store_false", help="Set this flag to use the transition dipole moments instead of a transition density fitted multipole expansion (see option --coupling-qfit-mom) to compute the coupling elements between the excited states of the chromophores.")
    cpl_group.add_argument("--coupling-qfit-mom", choices=[0], default=0, type=int, help="The order of the multipole moments (0 is charges, 1 is charges and dipoles and so on) used to compute the couplings. Choices are: %(choices)s. Default is %(default)s.")
    cpl_group.add_argument("--coupling-inddip-eps", default=1.0e-8, type=float, metavar="EPS", help="threshold for the convergence of the induced dipoles in the J1 term. Default is %(default)s.")
    cpl_group.add_argument("--coupling-cpus", default=coup_cpus, type=int, metavar="CPUS_PER_NODE", help="Number of cores to use for computing the Foerster coupling matrix.")

    INPUT_ARGS = ap.parse_args()
    print(INPUT_ARGS)

    # do some error handling
    if INPUT_ARGS.c is None:
        print("No chromophores specified. Aborting.")
        exit()

    if INPUT_ARGS.scratch_directory is None:
        print("ERROR: SPECTRE could not set temporary work directory.")
        print("       Please use SCRATCH or SPECTRE_TMPDIR environment variables")
        print("       or the --scratch option.")
        exit()

    if INPUT_ARGS.do_pde and not has_h5py:
        print("ERROR: SPECTRE could not run because you requested a ")
        print("       PDE-type calculation (--potential-do-pde) but ")
        print("       such a calculation requires the h5py package.")
        exit()

    # what follows here is the proposed workflow along required packages
    #
    # Basic input should be at *minimum*:
    #   - ONE .pdb file
    #   - a list of chromophores to be found in the file from above
    #
    # for a very large system it will be beneficial to run with multiple
    # .pdb files due to speed and complexity of the calculations but this
    # will be done at a later time
    #
    # 1. Identify Chromophores through residue names
    #   -c --chromophores [strings]
    #
    # the chromophores are labelled with residue names from the keyword -c
    # and are appropriately marked in the structures.
    #
    # To obtain the correct coupling (J = J0 + J1) we must also have embedding
    # parameters for these molecules (specifically for J1)
    #
    # 2. Generate embedding potential for everything using FragIt and CalcIt
    molecules, chromophores, potentials = setup_chromophores(INPUT_ARGS)

    # generate PDE potentials if needed.
    if INPUT_ARGS.do_pde:
        generate_pde_potentials(molecules, chromophores, potentials, INPUT_ARGS)

    #
    #
    # VIII. Computation of diagonal part of Foerster matrix along with
    # transition dipole moments (or transition density charges)
    properties = compute_chromophores(molecules, potentials, chromophores, INPUT_ARGS)

    if len(chromophores) > 1:
        exciton_energies, exciton_tr_dips, excitation_osc_str = couple_chromophores(molecules, chromophores, potentials, properties, INPUT_ARGS)

    cleanup_work_directories(molecules)
